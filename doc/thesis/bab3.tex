%-----------------------------------------------------------------------------%
\chapter{\babTiga}
\label{chap:babTiga}
%-----------------------------------------------------------------------------%

Pada bab ini dijelaskan mengenai tahapan penelitian, seperti yang ditunjukkan pada Tabel \ref{tab:tahapan_penelitian}, yang meliputi studi literatur, perancangan dan implementasi sistem, serta evaluasi dan analisis.

\begin{table}
\centering
\caption{Tahapan penelitian}
\label{tab:tahapan_penelitian}
\begin{tabular}{p{3.5cm} p{4.5cm} p{4.5cm}}
\hline
\textbf{Tahapan} & \textbf{Alat} & \textbf{Hasil} \\
\hline
Studi literatur & Mesin pencari buku dan jurnal elektronik & Latar belakang masalah, rumusan masalah, rangkuman penelitian terkait dan ide rancangan sistem \\
\hline
Perancangan dan pengimplentasian sistem & Java, Python, Git, editor kode & Sistem Open IE \\
\hline
Evaluasi dan analisis & Python & Tabel hasil, diagram hasil, kesimpulan dan saran \\
\hline
\end{tabular}
\end{table}

%-----------------------------------------------------------------------------%
\section{Studi Literatur}
%-----------------------------------------------------------------------------%

Pada tahap ini \saya~mengumpulkan dan menelaah dokumen ilmiah seperti \textit{paper} dan artikel elektronik terkait \textit{open IE} untuk memahami topik ini secara lebih mendalam dan mengetahui pencapaian penelitian-penelitian terkait. Pencarian dilakukan digunakan menggunakan mesin pencari\footnote{Database Jurnal Universitas Indonesia \url{http://remote-lib.ui.ac.id}}\footnote{Google Scholar \url{https://scholar.google.co.id/}} jurnal dan artikel ilmiah elektronik nasional dan internasional. Hasil penelaahan ini berupa latar belakang dan rumusan masalah yang dituangkan pada bab \ref{chap:babSatu}, rangkuman dan perbandingan sistem \textit{open IE} pada bab \ref{chap:babDua}, serta ide rancangan sistem \textit{open IE} untuk bahasa Indonesia yang akan dijelaskan pada subbab berikutnya.

%-----------------------------------------------------------------------------%
\section{Rancangan dan Implementasi Sistem}
%-----------------------------------------------------------------------------%

Pada tahap ini \saya~merancang sistem \textit{open IE} untuk bahasa Indonesia yang mengadaptasi beberapa teknik pada sistem \textit{open IE} pada penelitian terkait. Rancangan sistem ini berisi empat modul utama, seperti yang ditunjukkan pada Gambar \ref{fig:program_flowchart}, yaitu \textbf{NLP pipeline}, \textbf{triple candidate generator}, \textbf{triple selector} dan \textbf{token expander}. Terdapat tiga fase atau langkah untuk melakukan ekstraksi \textit{triple} menggunakan sistem ini:

\begin{enumerate}
	\item Label (\textit{label}): membangun data latih untuk untuk \textit{triple selector} dengan menganotasi manual kandidat \textit{triple} yang dihasilkan oleh \textit{triple candidate generator} dan \textit{NLP pipeline}.  
	\item Belajar (\textit{learn}): melatih \textit{triple selector} untuk mengekstrak himpunan \textit{triple} dari kalimat menggunakan data dari fase Label. Hasil dari fase ini adalah model yang dipakai pada fase berikutnya.
	\item Ekstrak (\textit{extract}): mengekstrak himpunan \textit{triple} dari kalimat menggunakan \textit{NLP pipeline}, \textit{triple candidate generator}, \textit{token expander} dan \textit{triple selector} yang telah dilatih pada fase Belajar. Alur kerja pada fase ini ditunjukkan pada Gambar \ref{fig:program_flowchart}.
\end{enumerate}



\begin{figure}
\centering
\includegraphics[width=\textwidth]{../images/program_flowchart.png}
\caption{Indonesian open domain information extraction flowchart}
\label{fig:program_flowchart}
\end{figure}

\subsection{NLP Pipeline}

\textit{NLP pipeline} adalah modul yang berisi serangkaian \textit{NLP task} yang menganotasi kalimat bahasa Indonesia dan menyimpannya sebagai dokumen dengan format CoNLL-U. Modul ini menerima dokumen teks yang berisi satu atau lebih kalimat yang dipisahkan oleh karakter baris baru (\textit{newline}) dan menghasilkan dokumen teks berisi kalimat yang telah dipotong menjadi \textit{token} dan diberi anotasi dengan format CoNLL-U. \textit{NLP task} yang terdapat pada rangkaian ini adalah sebagai berikut:

\begin{enumerate}

\item \textit{Tokenizer} \\
\textit{Tokenizer} yang digunakan pada rangkaian ini adalah yang disediakan pustaka \textit{Stanford Core NLP}, \verb|PTBTokenizer| \citep{manningptbtokenizer}. \textit{Tokenizer} berbasis aturan (\textit{rule-based}) ini mengikuti \textit{tokenizer} yang digunakan untuk menghasilkan \textit{Penn Treebank 3}\footnote{\textit{Penn Treebank 3} \url{https://catalog.ldc.upenn.edu/LDC99T42}} (\textit{treebank} bahasa Inggris). Meskipun \textit{tokenizer} ini menyediakan opsi untuk menyesuaikan proses dengan bahasa lain, di penelitian ini kami hanya menggunakan opsi standar untuk memotong kalimat berdasarkan \textit{whiteline} untuk mendapatkan \textit{token}.

\textit{Part of Speech Tagger} (\textit{POS tagger}) yang digunakan pada rangkaian ini adalah, \verb|MaxentTagger| \citep{toutanova2003feature}, yang juga merupakan bagian dari pustaka \textit{Stanford Core NLP}. \textit{POS tagger} berbasis \textit{multi-class logistic regression} ini dilatih dengan data yang diperoleh dengan mengekstraksi \textit{POS tag} dari 5.036 kalimat \textit{treebank} \textit{universal dependency} (UD) bahasa Indonesia\footnote{UD \textit{treebank} Indonesia \url{https://github.com/UniversalDependencies/UD_Indonesian}}. Hasil pengujian model \textit{POS tagger} ini, menggunakan 559 kalimat lain dari sumber yang sama, mencapai akurasi per token \textbf{93.68\%} dan akurasi per kalimat \textbf{63.91\%} (seluruh token dalam kalimat dianotasi dengan \textit{POS tag} yang benar).

\item \textit{Lemmatizer} \\
\textit{Lemmatizer} yang digunakan pada rangkaian ini diadaptasi dari \textit{lemmatizer} bahasa Indonesia berbasis aturan \citep{suhartono2014lemmatization} dan diberi nama \verb|IndonesianLemmaAnnotator|. Adaptasi dilakukan dengan melakukan perubahan berikut:

\begin{itemize}
\item Kemampuan untuk memproses tidak hanya kata tapi juga kalimat
\item Peningkatan kecepatan dengan penggunaan \textit{in-memory database}
\item Meningkatan \textit{reusability} dengan implementasi ulang menggunakan Java serta integrasi dengan pustaka \textit{Stanford Core NLP}
\end{itemize}

\textit{Lemmatizer} ini mencapai akurasi \textbf{99\%} saat diuji dengan 5.638 pasangan kata dan \textit{lemma} bahasa Indonesia dari \cite{suhartono2014lemmatization}.

\item \textit{Named-Entity Recognizer} (NER)

Stanford NLP \verb|CRFClassifier| \citep{finkel2005incorporating}, a linear chain Conditional Random Field (CRF) sequence models, is trained using a dataset containing 3,535 Indonesian sentences with 5 entity class: Person, Organization, Location, Quantity and Time. When tested using 426 sentences, this models achieves 0.86 precision, 0.85 recall and \textbf{0.86} F1-score. The dataset itself is a combination between dataset from Faculty of Computer Science, University of Indonesia and a public dataset\footnote{Indonesian NER \url{https://github.com/yusufsyaifudin/indonesia-ner}}. \\



\item Dependency Parser

We relied on Stanford NLP \verb|nndep.DependencyParser| \citep{chen2014fast}, to annotate dependency relation of each token in the sentence. We train this transition-based neural network model using a Indonesian universal dependencies dataset of 5,036 sentences and 3,093 Indonesian word embedding\footnote{Indonesian word embedding \url{https://github.com/yohanesgultom/id-openie/blob/master/data/parser-id.embed}} (vector representation of words). Tested with 559 sentences, this model scores \textbf{70\%} UAS (Unlabeled Attachment Score) and \textbf{46\%} LAS (Labeled Attachment Score).

\end{enumerate}

The output of the pipeline is a CONLL-U document containing annotated sentence such as Figure \ref{fig:conllu_example}. The document becomes an input for next model, the triple candidate generator which is described in Section \ref{Triple Candidate Generator}. Since the annotations that are directly used by following process are POS tag, named entity and dependency relation, we estimate that the accuracy of this NLP pipeline is \textbf{65.30\%} which comes from the average of POS tagger sentence accuracy, NER F1-score (in percent) and dependency parser LAS. Additionally, this pipeline is built by extending Stanford Core NLP classes and packaged as single Java program (JAR) to improve reusability.

\begin{figure}
\centering
\includegraphics[scale=0.35]{../images/conllu_example.png}
\caption{Example of CONLL-U sentence annotation format}
\label{fig:conllu_example}
\end{figure}

\subsection{Triple Candidate Generator} \label{Triple Candidate Generator}

% Similar to TextRunner Self-Supervised Learner but doesn't automatically label triples

Triple candidate generator is used to extract relation triples candidates from CONLL-U document produced by NLP pipeline. It uses a set of rules listed in Table \ref{tab:triple_candidate_generation_rules} to extract relations (predicates) and arguments (subjects and predicates) from the sentence. The results of triples extraction are not always the positive or valid relation triples so, unlike TextRunner \citep{banko2007open}, we cannot use them directly as training data for triple selector/classifier.

For example, applying the rules to an annotated sentence in Figure \ref{fig:conllu_example} will generate these 17 triples candidates where only five of them are valid triples (check-marked):

\begin{itemize}
\item (Sembungan, adalah, desa) \ding{51}
\item (Sembungan, adalah, terletak)
\item (Sembungan, adalah, kecamatan)
\item (Sembungan, adalah, kabupaten)
\item (Sembungan, adalah, Jawa)
\item (Sembungan, adalah, Tengah)
\item (Sembungan, adalah, Indonesia)
\item (Sembungan, terletak, kecamatan) \ding{51}
\item (Sembungan, terletak, kabupaten) \ding{51}
\item (Sembungan, terletak, Jawa) \ding{51}
\item (Sembungan, terletak, Tengah)
\item (Sembungan, terletak, Indonesia) \ding{51}
\item (desa, terletak, kecamatan)
\item (desa, terletak, kabupaten)
\item (desa, terletak, Jawa)
\item (desa, terletak, Tengah)
\item (desa, terletak, Indonesia)
\end{itemize}

In order to build a training data for the triple selector, we used triple candidate generator to generate 1,611 triple candidates from 42 sentences. As part of the label step, we manually label \textbf{132 positive} and \textbf{1,479 negative} triples which we use to train binary classifier as triple selector in the learn step.

During the extraction step, triple candidate generator is used in the system to extract unlabeled candidates from CONLL-U document. These unlabeled triples will be labeled by trained triple selector as described in  (referring to flowchart in Figure \ref{fig:program_flowchart}).

% Triple candidate generation rules
\begin{table}[!t]
\renewcommand{\arraystretch}{1.5}
\caption{Triple candidate generation rules}
\label{tab:triple_candidate_generation_rules}
\centering
\begin{tabular}{l p{6cm}}
\hline
\textbf{Type} & \textbf{Condition} \\
\hline
Subject & Token's POS tag is either PROPN, NOUN, PRON or VERB \\
\space & Token is not "yang" nor "adalah" \\
\space & Token's dependency is neither "compound" nor "name" \\
\space & Token's dependency is either "compound" or "name" but separated by more than 2 tokens from its head \\
\hline
Predicate & Token's position is after Subject \\
\space & Token's POS tag is either VERB or AUX \\
\hline
Object & Token's position is after Subject and Predicate \\
\space & Token's POS tag is either PROPN, NOUN, PRON or VERB \\
\space & Token is not "yang" nor "adalah" \\
\space & Token's dependency is neither "compound" nor "name" \\
\space & Token's dependency is either "compound" or "name" but separated by more than 2 tokens from its head \\
\end{tabular}
\end{table}


\subsection{Triple Selector}  \label{Triple Selector}

Triple selector is a machine learning classifier trained using manually labeled dataset of valid and invalid relation triples. For example, given the input of 17 candidates in Section \ref{Triple Candidate Generator}, the selector will label the five check-marked triples as true and label the rest as false.

We use Random Forest \citep{breiman2001random}, an ensemble methods that aggregate classification results from multiple decision trees, as the model for the classifier. We use the Scikit-Learn\footnote{scikit-learn: machine learning in Python \url{http://scikit-learn.org}} implementation of Random Forest with following configuration:

\begin{itemize}
\item Decision tree criterion: Gini Impurity
\item Minimum number of samples to split tree node: 5 samples
\item Maximum features used in each tree: 4 (square root of the number of features)
\item Maximum trees depth: 8
\item Number of trees: 20
\item Class weight: balanced (prediction probability is multiplied by the ratio of training samples)
\end{itemize}

We discover the configuration by using Grid Search \citep{wasserman2015grid}, an exhaustive search algorithm to find optimal hyper-parameters, to find the best F1 score for Random Forest classifier using dataset described in Section \ref{Triple Candidate Generator}. 

We extract 17 features described in Table \ref{tab:models_features} from each triple candidates. These features are based on POS tag, named-entity and dependency relation, instead of shallow syntactic features used by TextRunner or ReVerb \citep{banko2007open} \citep{etzioni2011open}. Every nominal features are also encoded and normalized along with the whole dataset by removing the mean and scaling to unit variance in order to improve the precision and recall of the classifier.

\begin{table}[!t]
\renewcommand{\arraystretch}{1.5}
\caption{Triple selector features}
\label{tab:models_features}
\centering
\begin{tabular}{r l}
\hline
\textbf{\#} & \textbf{Triple Features} \\
\hline
1 & Subject token's POS tag \\
2 & Subject token's dependency relation \\
3 & Subject token's head POS tag \\
4 & Subject token's named entity \\
5 & Subject token's distance from predicate \\
6 & Subject token's dependency with predicate \\
7 & Predicate token's POS tag \\
8 & Predicate token's dependency relation \\
9 & Predicate token's head POS tag \\
10 & Predicate token's dependents count \\
11 & Object token's POS tag \\
12 & Object token's dependency relation \\
13 & Object token's head POS tag \\
14 & Object token's named entity \\
15 & Object token's dependents count \\
16 & Object token's distance from predicate \\
17 & Object token's dependency with predicate \\
\end{tabular}
\end{table}

During the train step, we use the dataset to train triple selector and save the best model as binary file. This model is included in the system to be use during the extraction step.

\subsection{Token Expander}

Instead of using lightweight noun phrase chunker \citep{banko2007open}, our system uses rule-based token expander to extract relation or argument clauses. While having different objective and approach, this token expander works similarly to Clause Selector in Stanford Open IE \citep{angeli2015leveraging} where the algorithm starts from a token then decides whether to expand to its dependents. Instead of using machine learning model like Clause Selector, it uses simple heuristics based on syntactical features (POS tag, dependency relation and named-entity) described in Table \ref{tab:token_expansion_rules_s_o} and Table \ref{tab:token_expansion_rules_p} to determine whether to: (1) expand a token to its dependent, (2) ignore the dependent or (3) remove the token itself. For example, token expander will expand check-marked triples in Section \ref{Triple Candidate Generator} into:

\begin{itemize}
\item (Sembungan, adalah, desa)
\item (Sembungan, terletak di, kecamatan Kejajar)
\item (Sembungan, terletak di, kabupaten Wonosobo)
\item (Sembungan, terletak di, Jawa Tengah)
\item (Sembungan, terletak di, Indonesia)
\end{itemize}

% Token expansion rules for Subject or Object token
\begin{table}[!t]
\renewcommand{\arraystretch}{1.5}
\caption{Token expansion rules for Subject or Object token}
\label{tab:token_expansion_rules_s_o}
\centering
\begin{tabular}{r p{6cm} l}
\hline
\textbf{\#} & \textbf{Condition for Subject or Object Token} & \textbf{Action} \\
\hline
1 & If dependent's relation to the token  is either “compound”, “name”  or “amod” & Expand \\
2 & If dependent has same named entity as the token & Expand \\
3 & If dependent and the token are wrapped by quotes or double quotes  & Expand \\
4 & If the head is a sentence root & Ignore \\
5 & If dependent's POS tag is CONJ or its form is either “,” (comma) or “/” (slash) & Ignore \\
6 & If dependent's POS tag is either “VERB” or “ADP” & Ignore \\
7 & If dependent has at least one dependent with “ADP” POS tag & Ignore \\
8 & If the first or last token in expansion result has “CONJ” or “ADP” POS tag & Remove \\
9 & If the first or last index of expansion result is an incomplete parentheses symbol & Remove \\
10 & If the last index of expansion result is “yang” & Remove \\
11 & Else & Ignore \\
\hline
\end{tabular}
\end{table}

\begin{table}[!t]
\renewcommand{\arraystretch}{1.5}
\caption{Token expansion rules for Predicate token}
\label{tab:token_expansion_rules_p}
\centering
\begin{tabular}{r p{6cm} l}
\hline
\textbf{\#} & \textbf{Condition for Predicate Token} & \textbf{Action} \\
\hline
1 & If dependent is “tidak” & Expand \\
2 & Else & Ignore \\
\hline
\end{tabular}
\end{table}

During the label step, token expander is used to make manual annotation process easier. We label a triple candidate as valid only if it makes sense after being expanded to clause. For example, \textit{(Sembungan, terletak, kecamatan)} doesn't seem to make sense before expanded to \textit{(Sembungan, terletak di, kecamatan Kejajar)}.

%-----------------------------------------------------------------------------%
\section{Pengumpulan Data}
%-----------------------------------------------------------------------------%


Kamus lemma \url{https://github.com/davidchristiandy/lemmatizer} (5,638 kata uji)

Dataset POS tagging \url{https://github.com/UniversalDependencies/UD_Indonesian} (5,036 kalimat latih + 559 kalimat uji)

Dataset NER Kelas NLP Fasilkom, UI, 2016 \url{https://github.com/yohanesgultom/knowledge-extractor-id} (1,700 kalimat latih  + 426 kalimat uji, 3 kelas entitas: Person, Organization, Location) \url{https://github.com/yusufsyaifudin/indonesia-ner} (1,835 kalimat latih, 5 kelas entitas: Person, Organization, Location, Quantity, Time)

Dataset Dependency parsing \url{https://github.com/UniversalDependencies/UD_Indonesian} (5,036 kalimat latih + 559 kalimat uji)

Dataset triple selector, anotasi manual dari sebagian dataset dependency parsing

%-----------------------------------------------------------------------------%
\section{Evaluasi dan Analisis}
%-----------------------------------------------------------------------------%

Untuk mengevaluasi kinerja dari algoritma \textit{supervised learning} dilakukan proses validasi silang (\textit{cross validation}) menggunakan data yang sudah diketahui kelasnya.