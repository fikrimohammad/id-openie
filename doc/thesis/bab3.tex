%-----------------------------------------------------------------------------%
\chapter{\babTiga}
\label{chap:babTiga}
%-----------------------------------------------------------------------------%

Pada bab ini dijelaskan mengenai tahapan penelitian, seperti yang ditunjukkan pada Tabel \ref{tab:tahapan_penelitian}, yang meliputi studi literatur, perancangan dan implementasi sistem, serta evaluasi dan analisis.

\begin{table}
\centering
\caption{Tahapan penelitian}
\label{tab:tahapan_penelitian}
\begin{tabular}{p{3.5cm} p{4.5cm} p{4.5cm}}
\hline
\textbf{Tahapan} & \textbf{Alat} & \textbf{Hasil} \\
\hline
Studi literatur & Mesin pencari buku dan jurnal elektronik & Latar belakang masalah, rumusan masalah, rangkuman penelitian terkait dan ide rancangan sistem \\
\hline
Perancangan dan pengimplentasian sistem & Java, Python, Git, editor kode & Sistem Open IE \\
\hline
Evaluasi dan analisis & Python & Tabel hasil, diagram hasil, kesimpulan dan saran \\
\hline
\end{tabular}
\end{table}

%-----------------------------------------------------------------------------%
\section{Studi Literatur}
%-----------------------------------------------------------------------------%

Pada tahap ini \saya~mengumpulkan dan menelaah dokumen ilmiah seperti \textit{paper} dan artikel elektronik terkait \textit{open IE} untuk memahami topik ini secara lebih mendalam dan mengetahui pencapaian penelitian-penelitian terkait. Pencarian dilakukan digunakan menggunakan mesin pencari\footnote{Database Jurnal Universitas Indonesia \url{http://remote-lib.ui.ac.id}}\footnote{Google Scholar \url{https://scholar.google.co.id/}} jurnal dan artikel ilmiah elektronik nasional dan internasional. Hasil penelaahan ini berupa latar belakang dan rumusan masalah yang dituangkan pada bab \ref{chap:babSatu}, rangkuman dan perbandingan sistem \textit{open IE} pada bab \ref{chap:babDua}, serta ide rancangan sistem \textit{open IE} untuk bahasa Indonesia yang akan dijelaskan pada subbab berikutnya.

%-----------------------------------------------------------------------------%
\section{Rancangan dan Implementasi Sistem}
%-----------------------------------------------------------------------------%

Pada tahap ini \saya~merancang sistem \textit{open IE} untuk bahasa Indonesia yang mengadaptasi beberapa teknik pada sistem \textit{open IE} pada penelitian terkait. Rancangan sistem ini berisi empat modul utama, seperti yang ditunjukkan pada Gambar \ref{fig:program_flowchart}, yaitu \textbf{NLP pipeline}, \textbf{triple candidate generator}, \textbf{triple selector} dan \textbf{token expander}. Terdapat tiga fase atau langkah untuk melakukan ekstraksi \textit{triple} menggunakan sistem ini:

\begin{enumerate}
	\item Label (\textit{label}): membangun \textit{dataset} untuk untuk \textit{triple selector} dengan menganotasi manual kandidat \textit{triple} yang dihasilkan oleh \textit{triple candidate generator} dan \textit{NLP pipeline}.  
	\item Belajar (\textit{learn}): melatih \textit{triple selector} untuk mengekstrak himpunan \textit{triple} dari kalimat menggunakan \textit{dataset} dari fase Label. Hasil dari fase ini adalah model yang dipakai pada fase berikutnya.
	\item Ekstrak (\textit{extract}): mengekstrak himpunan \textit{triple} dari kalimat menggunakan \textit{NLP pipeline}, \textit{triple candidate generator}, \textit{token expander} dan \textit{triple selector} yang telah dilatih pada fase Belajar. Alur kerja pada fase ini ditunjukkan pada Gambar \ref{fig:program_flowchart}.
\end{enumerate}



\begin{figure}
\centering
\includegraphics[width=\textwidth]{../images/program_flowchart.png}
\caption{Indonesian open domain information extraction flowchart}
\label{fig:program_flowchart}
\end{figure}

\subsection{NLP Pipeline}

\textit{NLP pipeline} adalah modul yang berisi serangkaian \textit{NLP task} yang menganotasi kalimat bahasa Indonesia dan menyimpannya sebagai dokumen dengan format CoNLL-U. Modul ini menerima dokumen teks yang berisi satu atau lebih kalimat yang dipisahkan oleh karakter baris baru (\textit{newline}) dan menghasilkan dokumen teks berisi kalimat yang telah dipotong menjadi \textit{token} dan diberi anotasi dengan format CoNLL-U. Rangkaian ini diimplementasikan menggunakan pustaka \textit{Stanford Core NLP}, seperti yang ditunjukkan pada berkas \verb|DependencyParser.java| pada lampiran, dan didistribusikan dalam format \textit{Java Archieve} (JAR) sehingga mudah dintegrasikan dengan modul lain. \textit{NLP task} yang terdapat pada rangkaian ini adalah sebagai berikut:

\begin{enumerate}

\item \textit{Tokenizer} \\
\textit{Tokenizer} yang digunakan pada rangkaian ini adalah yang disediakan pustaka \textit{Stanford Core NLP}, \verb|PTBTokenizer| \citep{manningptbtokenizer}. \textit{Tokenizer} berbasis aturan (\textit{rule-based}) ini mengikuti \textit{tokenizer} yang digunakan untuk menghasilkan \textit{Penn Treebank 3}\footnote{\textit{Penn Treebank 3} \url{https://catalog.ldc.upenn.edu/LDC99T42}} (\textit{treebank} bahasa Inggris). Meskipun \textit{tokenizer} ini menyediakan opsi untuk menyesuaikan proses dengan bahasa lain, di penelitian ini kami hanya menggunakan opsi standar untuk memotong kalimat berdasarkan \textit{whiteline} untuk mendapatkan \textit{token}.

\textit{Part of Speech Tagger} (\textit{POS tagger}) yang digunakan pada rangkaian ini adalah, \verb|MaxentTagger| \citep{toutanova2003feature}, yang juga merupakan bagian dari pustaka \textit{Stanford Core NLP}. \textit{POS tagger} berbasis \textit{multi-class logistic regression} ini dilatih dengan \textit{dataset} yang diperoleh dengan mengekstraksi \textit{POS tag} dari 5,036 kalimat \textit{treebank} \textit{universal dependency} (UD) bahasa Indonesia\footnote{UD \textit{treebank} Indonesia \url{https://github.com/UniversalDependencies/UD_Indonesian}}. Hasil pengujian model \textit{POS tagger} ini, menggunakan 559 kalimat lain dari sumber yang sama, mencapai akurasi per token \textbf{93.68\%} dan akurasi per kalimat \textbf{63.91\%} (seluruh token dalam kalimat dianotasi dengan \textit{POS tag} yang benar).

\item \textit{Lemmatizer} \\
\textit{Lemmatizer} yang digunakan pada rangkaian ini diadaptasi dari \textit{lemmatizer} bahasa Indonesia berbasis aturan \citep{suhartono2014lemmatization} dan diberi nama \verb|IndonesianLemmaAnnotator|. Adaptasi dilakukan dengan melakukan perubahan berikut:

\begin{itemize}
\item Kemampuan untuk memproses tidak hanya kata tapi juga kalimat
\item Peningkatan kecepatan dengan penggunaan \textit{in-memory database}
\item Meningkatan \textit{reusability} dengan implementasi ulang menggunakan Java serta integrasi dengan pustaka \textit{Stanford Core NLP}
\end{itemize}

\textit{Lemmatizer} ini mencapai akurasi \textbf{99\%} saat diuji dengan 5.638 pasangan kata dan \textit{lemma} bahasa Indonesia dari \cite{suhartono2014lemmatization}.

\item \textit{Named-Entity Recognizer} (NER) \\
\textit{Named-entity recognizer} (NER) yang digunakan dalam rangkaian ini adalah \verb|CRFClassifier| \citep{finkel2005incorporating} dari pustaka \textit{Stanford Core NLP}. NER berbasis \textit{Conditional Random Field (CRF) sequence models} ini dilatih dan diuji menggunakan \textit{dataset} yang didapatkan dari dua sumber, yaitu dari Fakultas Ilmu Komputer, Universitas Indonesia dan dari repositori kode publik\footnote{NER Indonesia \url{https://github.com/yusufsyaifudin/indonesia-ner}}. \textit{dataset} ini berisi kalimat-kalimat yang setiap \textit{token}-nya yang relevan sudah diberi anotasi dari lima kelas: \textit{Person}, \textit{Organization}, \textit{Quantity} dan \textit{Time}. Hasil pelatihan dengan 3,535 kalimat dan pengujian dengan 426 kalimat adalah model yang mencapai rata-rata presisi 0.86, \textit{recall} 0.85 dan \textit{$F_1$-score} \textbf{0.86}.

\item \textit{Dependency Parser} \\
\textit{Dependency parser} yang digunakan dalam rangkaian ini adalah salah satu modul dalam pustaka \textit{Standford Core NLP}, yaitu \verb|nndep.DependencyParser| \citep{chen2014fast}. \textit{Dependency parser} ini berbasiskan jaringan syaraf tiruan (\textit{artificial neural network}) yang mempelajari pola transisi antar \textit{token} dalam kalimat dalam membentuk \textit{dependency tree}. \textit{\textit{dataset}set} yang digunakan untuk melatih dan menguji \textit{dependency parser} ini diperoleh dari \textit{treebank} \textit{universal dependency} (UD) bahasa Indonesia (sama dengan yang digunakan untuk \textit{POS tagger}). Model yang dihasilkan dengan melatih \textit{dependency parser} menggunakan 5,036 kalimat bahasa Indonesia ini mencapai nilai \textbf{70\%} UAS (\textit{Unlabeled Attachment Score}) dan \textbf{46\%} LAS (\textit{Labeled Attachment Score}) ketika diuji dengan 559 kalimat.

\end{enumerate}

Estimasi kinerja dari modul \textit{NLP pipeline} ini dihitung dari rata-rata kinerja \textit{POS tagger} (\textit{sentence accuracy}), \textit{NER} (\textit{$F_1$-score}) dan \textit{dependency parser} (LAS), yaitu \textbf{65.30\%}. Kinerja \textit{tokenizer} dan \textit{lemmatizer} tidak diperhitungkan karena dianggap sudah terwakili oleh \textit{NLP task} yang lain. Hasil dari \textit{NLP pipeline} ini adalah dokumen berisi anotasi setiap kalimat dengan format CoNLL-U seperti contoh pada Gambar \ref{fig:conllu_example}. Dokumen ini menjadi input bagi modul \textit{triple candidate generator} yang akan dijelaskan berikutnya. 

\begin{figure}
\centering
\includegraphics[width=\textwidth]{../images/conllu_example.png}
\caption{Contoh format CoNLL-U untuk sebuah kalimat}
\label{fig:conllu_example}
\end{figure}

\subsection{\textit{Triple Candidate Generator}} \label{Triple Candidate Generator}

Modul \textit{triple candidate generator} berfungsi untuk mengekstrak kandidat \textit{triple} dari dokumen CoNLL-U yang dihasilkan oleh \textit{NLP pipeline}. Modul ini menggunakan sejumlah aturan berbasis \textit{POS tag} dan \textit{dependency relation} yang ditampilkan pada Tabel \ref{tab:triple_candidate_generation_rules} untuk mengekstrak kandidat \textit{triple} dari tiap kalimat pada dokumen. Berbeda dengan \textsc{TextRunner} \citep{banko2007open} yang menghasilkan hanya menentukan kandidat yang valid secara otomatis, kandidat yang dihasilkan modul ini tidak semuanya valid sehingga diperlukan pelabelan oleh manusia (pada fase Label) atau pelabelan otomatis oleh \textit{classifier} (pada fase Extract) seperti pada \textsc{Stanford Open IE} \citep{angeli2015leveraging}. Modul ini diimplementasikan menggunakan bahasa pemrograman \textit{opensource} \textit{Python}\footnote{Python \url{https://www.python.org}} dengan fungsi utama \verb|extract_triples_by_combinations| pada berkas \verb|tripletools.py| yang disertakan pada lampiran.

% Triple candidate generation rules
\begin{table}
\renewcommand{\arraystretch}{1.5}
\caption{Aturan pembangkitan kandidat \textit{triple}}
\label{tab:triple_candidate_generation_rules}
\centering
\begin{tabular}{l p{12cm}}
\hline
\textbf{Jenis} & \textbf{Kondisi} \\
\hline
Subjek & \textit{POS tag} \textit{token} termasuk (PROPN, NOUN, PRON, VERB) \\
\space & \textit{Token} bukan termasuk ("yang", "adalah") \\
\space & \textit{Dependency} dari \textit{token} bukan termasuk ("compound", "name") \\
\space & \textit{Dependency} dari \textit{token} bukan termasuk ("compound", "name") tapi berjarak $>$ 2 dari \textit{head}-nya \\
\hline
Predikat & Posisi \textit{token} setelah Subjek \\
\space & \textit{POS tag} \textit{token} termasuk (VERB, AUX) \\
\hline
Objek & Posisi \textit{token} setelah Subjek dan Predikat \\
\space & \textit{POS tag} \textit{token} termasuk (PROPN, NOUN, PRON, VERB) \\
\space & \textit{Token} bukan termasuk ("yang", "adalah") \\
\space & \textit{Dependency} dari \textit{token} bukan termasuk ("compound", "name") \\
\space & \textit{Dependency} dari \textit{token} bukan termasuk ("compound", "name") tapi berjarak $>$ 2 dari \textit{head}-nya \\

\end{tabular}
\end{table}

Contoh aplikasi aturan \textit{triple candidate generator} pada contoh dokumen CoNLL-U pada Gambar \ref{fig:conllu_example} akan menghasilkan 17 kandidat \textit{triple} di mana hanya 5 di antaranya merupkan kandidat yang valid (ditandai dengan centang (\ding{51})):

\begin{itemize}
\item (Sembungan, adalah, desa) \ding{51}
\item (Sembungan, adalah, terletak)
\item (Sembungan, adalah, kecamatan)
\item (Sembungan, adalah, kabupaten)
\item (Sembungan, adalah, Jawa)
\item (Sembungan, adalah, Tengah)
\item (Sembungan, adalah, Indonesia)
\item (Sembungan, terletak, kecamatan) \ding{51}
\item (Sembungan, terletak, kabupaten) \ding{51}
\item (Sembungan, terletak, Jawa) \ding{51}
\item (Sembungan, terletak, Tengah)
\item (Sembungan, terletak, Indonesia) \ding{51}
\item (desa, terletak, kecamatan)
\item (desa, terletak, kabupaten)
\item (desa, terletak, Jawa)
\item (desa, terletak, Tengah)
\item (desa, terletak, Indonesia)
\end{itemize}

Untuk melatih modul \textit{triple selector} yang dapat memilih kandidat \textit{triple} yang valid, dibangun \textit{dataset} dengan melakukan pelabelan manual pada 1,611 kandidat \textit{triple} (132 positif dan 1,479 negatif) yang dihasilkan \textit{triple candidate generator} dari 42 kalimat berformat CoNLL-U. Himpunan kalimat tersebut merupakan sebagian dari \textit{dataset} \textit{universal dependency} Indonesia yang ditambahkan anotasi \textit{named-entity} secara manual.

Pada fase Ekstrak, \textit{triple candidate generator} juga digunakan untuk menghasilkan kandidat \textit{triple} dari dokumen CoNLL-U yang tidak berlabel seperti yang digambarkan pada Gambar \ref{fig:program_flowchart}. Hasil dari modul ini kemudian akan diseleksi oleh \textit{triple selector} yang telah dilatih pada fase Belajar. Lebih jauh mengenai \textit{triple} selector akan dijelaskan di subbab berikutnya.

\subsection{\textit{Triple Selector}}  \label{Triple Selector}

Modul \textit{triple selector} adalah sebuah \textit{supervised-learning classifier} yang dilatih untuk menyeleksi kandidat \textit{triple} yang dihasilkan oleh \textit{triple candidate generator}. Sebagai contoh, jika diberikan input 17 kandidat \textit{triple} yang disebutkan pada subbab \ref{Triple Candidate Generator}, modul ini akan mengambil lima kandidat \textit{triple} yang diberi tanda centang (\ding{51}) dan mengabaikan yang lainnya.

Metode yang digunakan untuk membangun \textit{classifier} pada modul ini adalah \textit{random forest} \citep{breiman2001random}, yang merupakan metode \textit{bagging} terhadap sejumlah \textit{decision tree}. Implementasi \textit{random forest} yang digunakan pada modul ini berasal dari pustaka \textit{scikit-learn}\footnote{scikit-learn \url{http://scikit-learn.org}} seperti yang ditunjukkan pada berkas \verb|classifier.py| (untuk fase Belajar) dan \verb|extract_triples.py| (untk fase Ekstrak) pada lampiran. Konfigurasi yang digunakan pada model \textit{random forest} pada modul ini adalah:

\begin{itemize}
\item Kriteria percabangan (\verb|criterion|): \textit{Gini Impurity}
\item Jumlah sampel minimal untuk membuat cabang  (\verb|min_samples_split|): 5
\item Jumlah fitur maksimum  (\verb|max_features|): 4 (akar dari jumlah total fitur)
\item Kedalaman maksimum  (\verb|max_depth|): 8
\item Jumlah pohon (\verb|n_estimators|): 20
\item Bobot kelas (\verb|class_weight|): \textit{balanced} (sesuai rasio kelas pada \textit{dataset})
\end{itemize}

Konfigurasi ini ditemukan dengan menggunakan algoritma \textit{grid search} \citep{wasserman2015grid}, algoritma pencarian menyeluruh (\textit{exhaustive}) terhadap sejumlah himpunan \textit{hyperparameter} untuk mengoptimalkan metrik evaluasi tertentu. Algoritma ini digunakan untuk mencari konfigurasi yang menghasilkan \textit{$F_1$ score} terbaik untuk \textit{random forest} dengan data yang ada.

Untuk melakukan klasifikasi, 17 fitur berbasis \textit{POS tag}, \textit{named-entity} dan \textit{dependency relation} diekstrak dari masing-masing kandidat \textit{triple} dengan rincian pada Tabel \ref{tab:models_features}. Berbeda dengan \textsc{TextRunner} atau \textsc{ReVerb} \citep{banko2007open} \citep{etzioni2011open} yang lebih memilih menggunakan \textit{shallow syntactic features}, \textit{classifier} pada sistem ini menggunakan \textit{heavy linguistic features} seperti \textit{dependency relation} untuk mengoptimalkan \textit{precision} dan \textit{recall}.

\begin{table}
\caption{Fitur klasifikasi \textit{triple selector}}
\label{tab:models_features}
\centering
\begin{tabular}{r l}
\hline
\textbf{\#} & \textbf{Fitur Klasifikasi} \\
\hline
1 & \textit{POS tag} dari \textit{token} Subjek \\
2 & \textit{Dependency relation} dari \textit{token} Subjek \\
3 & \textit{POS tag} dari \textit{head} \textit{token} Subjek \\
4 & \textit{Named-entity} dari \textit{token} Subjek \\
5 & Jarak Subjek ke \textit{token} Predikat \\
6 & \textit{Dependency relation} dari \textit{token} Subjek ke Predikat \\
7 & \textit{POS tag} dari \textit{token} Predikat \\
8 & \textit{Dependency relation} dari \textit{token} Predikat \\
9 & \textit{POS tag} dari \textit{head} \textit{token} Predikat \\
10 & Jumlah \textit{dependents} \textit{token} Predikat \\
11 & \textit{POS tag} dari \textit{token} Objek \\
12 & \textit{Dependency relation} dari \textit{token} Objek \\
13 & \textit{POS tag} dari \textit{head} \textit{token} Objek \\
14 & \textit{Named-entity} dari \textit{token} Objek \\
15 & Jumlah \textit{dependents} dari \textit{token} Objek \\
16 & Jarak dari \textit{token} Objek ke predikat \\
17 & \textit{Dependency relation} \textit{token} Objek ke Predikat  \\
\end{tabular}
\end{table}

Pada fase Belajar, data kandidat \textit{triple} yang telah diberi label di fase Label diekstrak menjadi 17 fitur yang dijelaskan di Tabel \ref{tab:models_features} dan dinormalisasi menggunakan pustaka \verb|StandardScaler| dari \textit{sckit-learn}. \textit{Dataset} berisi fitur yang telah dinormalisasi tersebut dipakai untuk melatih \textit{classifier} dan hasilnya juga disimpan dalam berkas biner (\textit{binary file}) untuk digunakan pada fase Ekstrak.

\subsection{\textit{Token Expander}}

Modul \textit{token expander} adalah berfungsi mengekspansi \textit{token} pada \textit{triple} menjadi kata, kata majemuk atau frase sehingga makna \textit{triple} menjadi lebih jelas. Contoh ekspansi \textit{token} terhadap lima kandidat \textit{triple} yang valid pada subbab \ref{Triple Candidate Generator} adalah:

\begin{itemize}
\item (Sembungan, adalah, desa)
\item (Sembungan, terletak di, kecamatan Kejajar)
\item (Sembungan, terletak di, kabupaten Wonosobo)
\item (Sembungan, terletak di, Jawa Tengah)
\item (Sembungan, terletak di, Indonesia)
\end{itemize}

Jika \textsc{TextRunner} menggunakan \textit{noun phrase chunker} \citep{banko2007open} untuk menemukan frase sebagai kandidat argumen (subjek atau objek), \textit{token expander} menggunakan 11 aturan berbasis \textit{POS tag}, \textit{named-entity} dan \textit{dependency relation} yang dirinci pada Tabel \ref{tab:token_expansion_rules_s_o}. Perbedaan lain dengan \textit{TextRunner} adalah modul ini digunakan juga untuk mengekspansi negasi \textit{token} predikat dengan aturan pada Tabel \ref{tab:token_expansion_rules_p}. Modul ini menelusuri setiap \textit{dependent} dari sebuah \textit{token} dan memutuskan apakah akan (1) melakukan ekspansi (\textit{expand}) ke \textit{dependent} tersebut, (2) mengabaikan (\textit{ignore}) \textit{dependent} tersebut, atau (3) membuang (\textit{remove}) \textit{dependent} tersebut. Sekalipun memiliki tujuan dan teknik yang berbeda dengan \textit{clause selector} pada \textsc{Stanford Open IE} \citep{angeli2015leveraging}, modul ini sama-sama membentuk frase dengan menelusuri \textit{dependent} dan memutuskan apakah sebuah \textit{dependent} merupakan bagian dari frase yang sama atau berbeda.


% Token expansion rules for Subject or Object token
\begin{table}
\caption{Aturan ekspansi untuk \textit{token} subjek atau objek}
\label{tab:token_expansion_rules_s_o}
\centering
\begin{tabular}{r p{10cm} l}
\hline
\textbf{\#} & \textbf{Kondisi untuk \textit{token} subjek atau objek} & \textbf{Aksi} \\
\hline
1 & Jika relasi \textit{dependent} di antara()["compound", "name", "amod") & Ekspansi \\
2 & Jika \textit{dependent} memiliki \textit{named-entity} yang sama dengan \textit{token}  & Ekspansi \\
3 & Jika \textit{dependent} dan token berada dalam kutipan (\textit{quote}) & Ekspansi \\
4 & Jika \textit{token} merupakan \textit{root} kalimat & Abaikan \\
5 & Jika \textit{POS tag} dependent CONJ atau termasuk simbol (",", "/) & Abaikan \\
6 & Jika \textit{POS tag} dependent termasuk ("VERB", "ADP")  & Abaikan \\
7 & Jika \textit{dependent} memiliki \textit{dependent} dengan \textit{POS tag} "ADP" & Abaikan \\
8 & Jika \textit{POS tag} \textit{dependent} di antara ("CONJ", "ADP") dan berada di depan frase & Buang \\
9 & Jika \textit{dependent} merupakan tanda kurung yang tidak lengkap & Buang \\
10 & Jika \textit{dependent} merupakan kata "yang" diakhir frase & Buang \\
11 & Lain-lain & Abaikan \\
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{Aturan ekspansi untuk \textit{token} predikat}
\label{tab:token_expansion_rules_p}
\centering
\begin{tabular}{r p{10cm} l}
\hline
\textbf{\#} & \textbf{Kondisi untuk \textit{token} predikat} & \textbf{Aksi} \\
\hline
1 & Jika \textit{dependent} adalah "tidak" & Ekspansi \\
2 & Lain-lain & Abaikan \\
\hline
\end{tabular}
\end{table}

Pada fase Label, \textit{token expander} digunakan untuk mengekspansi kandidat \textit{triple} yang dihasilkan \textit{triple candidate generator} sehingga lebih mudah dimengerti manusia. Sedangkan pada fase Ekstrak, modul ini mengekspansi \textit{triple} yang telah dipilih oleh \textit{triple selector} sehingga maknanya lebih jelas. Implementasi dari modul ini dibuat dengan \textit{Python}, yaitu pada fungsi \verb|flatten_node| dalam berkas \verb|tripletools.py| yang juga dilampirkan.

%-----------------------------------------------------------------------------%
\section{Evaluasi dan Analisis}
%-----------------------------------------------------------------------------%

\subsection{Evaluasi}

Evaluasi sistem \textit{open IE} ini akan difokuskan pada modul \textit{triple selector} karena modul ini ditopang oleh modul \textit{triple candidate generator} dan \textit{token expander} yang, bersama dengan \textit{triple selector}, merupakan pusat kontribusi dari penelitian ini. Selain karena tidak banyak kontribusi yang diberikan melalui modul \textit{NLP pipeline}, kinerja dari modul ini tidak dievaluasi secara khusus melainkan hanya akan dievaluasi secara tidak langsung pada evaluasi efisiensi sistem \textit{open IE} ini. Evaluasi pada penelitian ini akan dibagi menjadi dua eksperimen:

\subsubsection{Eksperimen Model \textit{Triple Selector}}

Pada eksperimen ini akan dibandingkan kinerja empat buah model \textit{supervised learning} untuk melakukan klasifikasi \textit{triple} untuk menentukan apakah \textit{random forest} \citep{wasserman2015grid} adalah model yang paling cocok. Empat buah model tersebut adalah \textit{linear logistic regression}  \citep{fan2008liblinear}, \textit{polynomial support vector machine} (SVM) \citep{chang2011libsvm}, \textit{multi-layer perceptron} (MLP) \citep{hinton1989connectionist} dan \textit{random forest} sendiri. Keempat model ini akan dilatih dan diuji dengan metode \textit{k-fold cross-validation} menggunakan \textit{dataset} yang telah dijelaskan pada subbab \ref{Triple Candidate Generator}. Karena \textit{dataset} yang digunakan memiliki rasio kelas positif dan negatif yang tidak seimbang, maka digunakan $k = 3$ pada \textit{cross-validation} untuk mencegah adanya potongan (\textit{fold}) \textit{dataset} yang hanya terdiri dari kelas negatif.

Metrik yang akan dibandingkan pada eksperimen ini adalah \textit{precision}, \textit{recall} dan \textit{$F_1$ score} hanya untuk kelas positif (\textit{triple} valid) karena pada \textit{open IE} data negatif tidak diperlukan. Karena untuk \textit{task} klasifikasi \textit{triple} ini \textit{precision} dan \textit{recall} sama-sama penting, maka metrik yang dipandang lebih penting adalah rerata dari dua metrik tersebut, yaitu \textit{$F_1$-score} \citep{angeli2015leveraging}. Persamaan untuk menghitung \textit{precision}, \textit{recall} dan \textit{$F_1$-score} untuk data positif ditunjukkan secara berurutan pada persamaan \ref{eq:precision}, \ref{eq:recall} dan \ref{eq:f1}.

\noindent \begin{align}\label{eq:precision}
	\textit{precision}_+ = \frac{|\textit{selected valid triples}|}{|\textit{selected triples}|}
\end{align}

\noindent \begin{align}\label{eq:recall}
	\textit{recall}_+ = \frac{|\textit{selected valid triples}|}{|\textit{valid triples}|}
\end{align}

\noindent \begin{align}\label{eq:f1}
	F_{1} = 2 \cdot \frac{\textit{precision}_+ \cdot \textit{recall}_+ }{ \textit{precision}_+ \, + \, \textit{recall}_+}
\end{align}


\subsubsection{Eksperimen Waktu Ekstraksi \textit{Triple}}

Pada eksperimen ini diukur waktu eksekusi total sistem \textit{open IE} yang diajukan pada tiga dokumen input yang memiliki jumlah kalimat yang bervariasi. Tujuan dari eksperimen ini adalah mengukur efisiensi sistem secara umum dan membandingkannya dengan penelitian terkait. Dokumen yang digunakan sebagai input pada eksperimen ini adalah:

\begin{enumerate}
\item Dokumen berisi 2 kalimat dari \textit{dataset} pelatihan
\item Dokumen berisi 138 kalimat dari proposal penelitian
\item Dokumen berisi 5,593 dari \textit{dataset} pelatihan
\end{enumerate}

\subsection{Analisis}

Analisis akan dilakukan terhadap hasil eksperimen yang telah dijelaskan di atas dengan tujuan mengukur pencapaian pada penelitian ini relatif terhadap penelitian-penelitian terkait, memapaparkan alasan di balik hasil eksperimen yang diperoleh serta mencari alternatif perbaikan atau peningkatan yang dapat dilakukan pada penelitian ini ke depannya.