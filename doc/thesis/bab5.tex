%-----------------------------------------------------------------------------%
\chapter{\babLima}
\label{chap:babLima}
%-----------------------------------------------------------------------------%

Pada bab ini dijelaskan kesimpulan penelitian ini dan saran untuk pengembangan penelitian di masa depan.

%-----------------------------------------------------------------------------%
\section{Kesimpulan}
%-----------------------------------------------------------------------------%

%This paper introduces an open domain information extraction system for Indonesian text using basic NLP pipelines and combination of heuristics and machine learning models. The system is able to extract meaningful domain-independent relations from Indonesian sentences to be used as document representation or document understanding task. Additionally, the source code and datasets are published openly\footnote{Paper source code \url{https://github.com/yohanesgultom/id-openie}} to improve research reproducibility.

Melalui penelitian ini telah diajukan rancangan sistem \textit{open IE} untuk bahasa Indonesia yang menggunakan \textit{NLP pipeline} dan kombinasi model heuristik dan \textit{supervised learning}. Sekalipun belum mencapai akurasi yang tinggi, implementasi sistem ini mampu mengekstraksi \textit{triple} dari teks atau dokumen bahasa Indonesia secara otomatis dalam waktu yang sebanding dengan sistem dari penelitian terkait. Pada penelitian ini juga dibangun \textit{dataset} untuk seleksi \textit{triple} dan dikumpulkan himpunan \textit{dataset} untuk \textit{NLP task} bahasa Indonesia yang dapat digunakan untuk penelitian terkait. Semua kode sumber dan \textit{dataset} penelitian ini juga dipublikasikan pada repositori publik\footnote{Repositori penelitian \url{github.com/yohanesgultom/id-openie}} untuk memudahkan replikasi. Kesimpulan yang dapat diambil berdasarkan evaluasi dan analisis dalam penelitian ini adalah:

\begin{enumerate}
	\item Kombinasi \textit{NLP pipeline} dasar (\textit{POS tagging}, \textit{lemmatization}, \textit{NER} dan \textit{dependency parsing}) berbasis \textit{Universal Dependency}, model heuristik dan \textit{supervised learning} dapat melakukan \textit{open domain information extraction} (\textit{open IE}) dalam format \textit{triple} (subjek, predikat, objek) dari teks bahasa Indonesia secara otomatis.
	
	\item Model \textit{supervised-learning} yang paling sesuai untuk melakukan seleksi \textit{triple} berdasarkan fitur berbasis \textit{POS tag}, \textit{named-entity} dan \textit{dependency relation} adalah \textit{random forest}, yang merupakan \textit{ensemble classifier}. Model ini mencapai nilai $F_1$ 0.58, yang lebih tinggi dari tiga model linier dan nonlinier lain yang diujikan.
	
	\item Sistem \textit{open IE} yang diajukan hanya membutuhkan waktu proses 0.02 detik/kalimat untuk dokumen berukuran 5,000 kalimat. Nilai ini cukup sebanding dengan yang dicapai oleh \textsc{TextRunner} \citep{banko2007open} sehingga mengindikasikan kinerja yang cukup baik. Disamping itu dapat disimpulkan juga bahwa sistem ini paling cocok digunakan untuk memproses dokumen dengan ukuran 5,000 kalimat. Jika diasumsikan trend yang ditampilkan pada grafik rata-rata waktu proses Gambar \ref{fig:system_performance} stabil dan mesin yang digunakan sanggup, maka sistem ini akan makin efisien seiring dengan bertambahnya ukuran dokumen.
\end{enumerate}


%-----------------------------------------------------------------------------%
\section{Saran}
%-----------------------------------------------------------------------------%

Berdasarkan hasil analisis, berikut adalah saran pengembangan penelitian ini ke depannya:

\begin{enumerate}
	\item Memperbaiki kualitas \textit{dataset} untuk melatih \textit{triple selector} dengan menambah lebih banyak data. Seperti yang dijelaskan pada bagian analisis, rendahnya hasil eksperimen \textit{cross-validation} dengan $K = 3$ menunjukkan bahwa pola pada $\nicefrac{2}{3}$ data yang ada tidak cukup untuk mengenali sisa pola $\nicefrac{1}{3}$ data yang dipakai untuk menguji. Oleh karena itu perlu ditambahkan sampel \textit{triple} yang lebih banyak dan beragam sampai setidaknya $\nicefrac{2}{3}$ mampu mencerminkan sebagian atau seluruh dari sisa $\nicefrac{1}{3}$ data.
	
	\item Mengembangkan \textit{triple candidate generator} untuk bisa mengekstraksi kandidat \textit{triple} implisit dan mengurangi kandidat \textit{triple} yang invalid. Timpangnya rasio sampel positif dan negatif dari \textit{dataset} yang dihasilkan \textit{triple candidate generator}, yaitu 1:11 menunjukkan bahwa aturan yang digunakan masih terlalu longgar. Perlu diteliti aturan-aturan yang dapat menyaring \textit{triple} yang invalid sehingga dapat dihasilkan \textit{dataset} yang seimbang (\textit{balanced}). Hal ini diharapkan dapat membuat sistem lebih efisien dan meningkatkan kinerja \textit{triple selector}.
	
	\item Menggunakan kombinasi antara \textit{ensemble classifier} seperti \textit{random forest} dan \textit{classifier} berpresisi tinggi seperti SVM sebagai \textit{triple selector} untuk meningkatkan \textit{precision} dan \textit{$F_1$ score}. Sekalipun pada eksperimen kalah dalam hal \textit{$F_1$ score} dari \textit{random forest}, SVM dinilai memiliki potensi karena unggul cukup jauh dalam hal presisi dari \textit{random forest} maupun model lainnya. Oleh karena itu perlu diteliti apakah penggabungan kedua model ini dapat mencapai hasil yang lebih baik.
	
	\item Melakukan pengujian sistem secara keseluruhan dengan dokumen yang lebih besar (berisi lebih banyak kalimat) serta membangun \textit{dataset} untuk bisa mengevaluasi keseluruhan sistem secara lebih \textit{reliable}. Meskipun kemampuan sistem secara keseluruhan dapat diaproksimasi dengan mengalikan akurasi \textit{NLP pipeline} dan \textit{triple selector} dan/atau menghitung secara manual akurasi hasil ekstraksi sistem, akan lebih ideal jika dibangun \textit{gold standard dataset} yang dapat dipakai untuk mengevaluasi sistem \textit{open IE} bahasa Indonesia terlepas dari cara kerjanya. Ukuran \textit{dataset} yang dikembangkan juga perlu dibuat cukup besar untuk mencerminkan ukuran dokumen yang diproses pada kasus nyata (\textit{realistic use case}).
	
\end{enumerate}
